# Text Moderation Annotation Project

## ğŸ“Œ Project Overview

This project contains a manually annotated text moderation dataset for NLP and content filtering practice.

The dataset includes text samples labeled across multiple moderation categories with confidence scores.

## ğŸ¯ Objective

The purpose of this project is to:

- Practice supervised content moderation classification
- Detect unsafe, spam, abusive, violent, hate speech, and sarcastic content
- Handle ambiguous moderation cases
- Build portfolio-ready AI and data annotation experience

## ğŸ—‚ Dataset Information

Total Samples: 50  
Annotation Type: Text Moderation Classification  

Each entry contains:

- ID
- TEXT
- LABEL
- CONFIDENCE_SCORE
- COMMENT (only for ambiguous cases)

## ğŸ· Moderation Categories Used

- Safe  
- Spam  
- Abusive  
- Violence  
- Hate Speech  
- Sarcastic  

## ğŸ“Š Annotation Approach

- Text was labeled according to its potential risk or harmful content.  
- Clear category texts were labeled with high confidence.  
- Ambiguous or mixed cases include explanatory comments.  

## ğŸš€ Possible Use Cases

- Social media content filtering  
- Chatbot moderation  
- Online community monitoring  
- AI model training for safe communication  

## ğŸ›  Tools Used

- Google Sheets (Data Annotation)  
- CSV format for structured dataset  
- GitHub for project hosting  

---

This project demonstrates practical understanding of text moderation and dataset structuring for NLP and AI applications.
